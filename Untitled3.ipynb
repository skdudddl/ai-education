{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skdudddl/ai-education/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WuKQOkKg4jHH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.datasets as ds\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D,GlobalAveragePooling2D,Flatten,Dense,Dropout, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "INyKe-Lv576x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518cdcd7-cc80-4940-f7b9-e5dacc71ad6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train,y_train),(x_test,y_test)=ds.cifar10.load_data()\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u4ep8sLLlv6e"
      },
      "outputs": [],
      "source": [
        "def frac_max_pooling(x):\n",
        "    return tf.nn.fractional_max_pool(x, [1.0, 1.41, 1.41, 1.0], pseudo_random = True, overlapping =True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "582StVf76AD7"
      },
      "outputs": [],
      "source": [
        "cnn=Sequential()\n",
        "cnn.add(Conv2D(32,(3,3),activation='relu',padding = 'same', input_shape=(32,32,3)))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(Conv2D(32,(3,3),activation='relu', padding = 'same'))\n",
        "cnn.add(BatchNormalization())\n",
        "#cnn.add(Lambda(frac_max_pooling))\n",
        "cnn.add(Dropout(0.3))\n",
        "\n",
        "cnn.add(Conv2D(64,(3,3),activation='leaky_relu', padding = 'same'))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(Conv2D(64,(3,3),activation='leaky_relu', padding = 'same'))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(Lambda(frac_max_pooling))\n",
        "cnn.add(Dropout(0.35))\n",
        "\n",
        "cnn.add(Conv2D(96,(3,3),activation='leaky_relu', padding = 'same'))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(Conv2D(96,(3,3),activation='leaky_relu', padding = 'same'))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(Lambda(frac_max_pooling))\n",
        "cnn.add(Dropout(0.4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(Conv2D(128,(3,3),activation='leaky_relu', padding = 'same'))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(Conv2D(128,(3,3),activation='leaky_relu', padding = 'same'))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(Lambda(frac_max_pooling))\n",
        "cnn.add(Dropout(0.45))\n",
        "\n",
        "# cnn.add(Conv2D(160,(3,3),activation='leaky_relu', padding = 'same'))\n",
        "# cnn.add(BatchNormalization())\n",
        "# cnn.add(Conv2D(160,(3,3),activation='leaky_relu', padding = 'same'))\n",
        "# cnn.add(BatchNormalization())\n",
        "# cnn.add(Lambda(frac_max_pooling))\n",
        "# cnn.add(Dropout(0.45))\n",
        "\n",
        "# cnn.add(Conv2D(192,(3,3),activation='leaky_relu', padding = 'same'))\n",
        "# cnn.add(BatchNormalization())\n",
        "# cnn.add(Conv2D(192,(3,3),activation='leaky_relu', padding = 'same'))\n",
        "# cnn.add(BatchNormalization())\n",
        "# cnn.add(Lambda(frac_max_pooling))\n",
        "# cnn.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(units=512,activation='relu'))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(units=10,activation='softmax'))"
      ],
      "metadata": {
        "id": "y6X6qSST3FME"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCzttdeR_Ftq"
      },
      "source": [
        "활성화 함수들중에서 elu, selu, relu중에서 선택하는데 chatgpt에서 물어본 결과 cifa10같은 작은 데이터셋에서는 selu와 relu의 성능차이가 크게 나타나지 않을 수 있다. 실제로도 둘의 성능을 비교하는 결과는 다양하다. 그래서 직접 수행하며 확인하는 결과 -> relu 보다 selu선택할건지\n",
        "relu 사용할 때 정확률 80\n",
        "selu는 정확률 76퍼로 relu 사용하는 게 더 성능 좋음\n",
        "그다음 leaky_relu쓴 결과 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0HxuMas6BKf",
        "outputId": "5d3bd37c-f614-4f2a-d49c-3c7f2c4606e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "782/782 - 161s - loss: 2.3633 - accuracy: 0.2297 - val_loss: 1.9377 - val_accuracy: 0.2469 - 161s/epoch - 206ms/step\n",
            "Epoch 2/100\n",
            "782/782 - 142s - loss: 1.7891 - accuracy: 0.2986 - val_loss: 1.5856 - val_accuracy: 0.3903 - 142s/epoch - 182ms/step\n",
            "Epoch 3/100\n",
            "782/782 - 139s - loss: 1.6485 - accuracy: 0.3645 - val_loss: 1.3688 - val_accuracy: 0.4809 - 139s/epoch - 178ms/step\n",
            "Epoch 4/100\n",
            "782/782 - 141s - loss: 1.4987 - accuracy: 0.4432 - val_loss: 1.2653 - val_accuracy: 0.5410 - 141s/epoch - 180ms/step\n",
            "Epoch 5/100\n",
            "782/782 - 139s - loss: 1.3554 - accuracy: 0.5101 - val_loss: 1.1978 - val_accuracy: 0.5766 - 139s/epoch - 178ms/step\n",
            "Epoch 6/100\n",
            "782/782 - 139s - loss: 1.2317 - accuracy: 0.5626 - val_loss: 0.9961 - val_accuracy: 0.6579 - 139s/epoch - 178ms/step\n",
            "Epoch 7/100\n",
            "782/782 - 136s - loss: 1.1437 - accuracy: 0.6008 - val_loss: 0.9190 - val_accuracy: 0.6829 - 136s/epoch - 174ms/step\n",
            "Epoch 8/100\n",
            "782/782 - 137s - loss: 1.0670 - accuracy: 0.6316 - val_loss: 0.9545 - val_accuracy: 0.6818 - 137s/epoch - 176ms/step\n",
            "Epoch 9/100\n",
            "782/782 - 138s - loss: 1.0018 - accuracy: 0.6577 - val_loss: 0.8506 - val_accuracy: 0.7204 - 138s/epoch - 176ms/step\n",
            "Epoch 10/100\n",
            "782/782 - 136s - loss: 0.9377 - accuracy: 0.6846 - val_loss: 0.8431 - val_accuracy: 0.7210 - 136s/epoch - 173ms/step\n",
            "Epoch 11/100\n",
            "782/782 - 138s - loss: 0.8984 - accuracy: 0.6987 - val_loss: 0.8054 - val_accuracy: 0.7274 - 138s/epoch - 177ms/step\n",
            "Epoch 12/100\n",
            "782/782 - 140s - loss: 0.8464 - accuracy: 0.7140 - val_loss: 0.7471 - val_accuracy: 0.7478 - 140s/epoch - 179ms/step\n",
            "Epoch 13/100\n",
            "782/782 - 136s - loss: 0.7926 - accuracy: 0.7346 - val_loss: 0.7548 - val_accuracy: 0.7508 - 136s/epoch - 174ms/step\n",
            "Epoch 14/100\n",
            "782/782 - 139s - loss: 0.7492 - accuracy: 0.7487 - val_loss: 0.6546 - val_accuracy: 0.7811 - 139s/epoch - 178ms/step\n",
            "Epoch 15/100\n",
            "782/782 - 135s - loss: 0.7043 - accuracy: 0.7669 - val_loss: 0.6473 - val_accuracy: 0.7863 - 135s/epoch - 173ms/step\n",
            "Epoch 16/100\n",
            "782/782 - 135s - loss: 0.6647 - accuracy: 0.7794 - val_loss: 0.5898 - val_accuracy: 0.8012 - 135s/epoch - 172ms/step\n",
            "Epoch 17/100\n",
            "782/782 - 136s - loss: 0.6286 - accuracy: 0.7895 - val_loss: 0.5661 - val_accuracy: 0.8111 - 136s/epoch - 174ms/step\n",
            "Epoch 18/100\n",
            "782/782 - 137s - loss: 0.5979 - accuracy: 0.8016 - val_loss: 0.5676 - val_accuracy: 0.8116 - 137s/epoch - 175ms/step\n",
            "Epoch 19/100\n",
            "782/782 - 137s - loss: 0.5596 - accuracy: 0.8113 - val_loss: 0.5839 - val_accuracy: 0.8060 - 137s/epoch - 175ms/step\n",
            "Epoch 20/100\n",
            "782/782 - 135s - loss: 0.5430 - accuracy: 0.8153 - val_loss: 0.5148 - val_accuracy: 0.8311 - 135s/epoch - 172ms/step\n",
            "Epoch 21/100\n",
            "782/782 - 134s - loss: 0.5162 - accuracy: 0.8238 - val_loss: 0.5099 - val_accuracy: 0.8347 - 134s/epoch - 172ms/step\n",
            "Epoch 22/100\n",
            "782/782 - 134s - loss: 0.4980 - accuracy: 0.8333 - val_loss: 0.5142 - val_accuracy: 0.8291 - 134s/epoch - 172ms/step\n",
            "Epoch 23/100\n",
            "782/782 - 135s - loss: 0.4730 - accuracy: 0.8384 - val_loss: 0.4688 - val_accuracy: 0.8503 - 135s/epoch - 172ms/step\n",
            "Epoch 24/100\n",
            "782/782 - 135s - loss: 0.4523 - accuracy: 0.8470 - val_loss: 0.4958 - val_accuracy: 0.8381 - 135s/epoch - 173ms/step\n",
            "Epoch 25/100\n",
            "782/782 - 136s - loss: 0.4387 - accuracy: 0.8524 - val_loss: 0.5295 - val_accuracy: 0.8301 - 136s/epoch - 174ms/step\n",
            "Epoch 26/100\n",
            "782/782 - 135s - loss: 0.4170 - accuracy: 0.8584 - val_loss: 0.5418 - val_accuracy: 0.8212 - 135s/epoch - 172ms/step\n",
            "Epoch 27/100\n",
            "782/782 - 136s - loss: 0.4038 - accuracy: 0.8627 - val_loss: 0.4427 - val_accuracy: 0.8550 - 136s/epoch - 174ms/step\n",
            "Epoch 28/100\n",
            "782/782 - 136s - loss: 0.3901 - accuracy: 0.8668 - val_loss: 0.5115 - val_accuracy: 0.8401 - 136s/epoch - 174ms/step\n",
            "Epoch 29/100\n",
            "782/782 - 135s - loss: 0.3811 - accuracy: 0.8700 - val_loss: 0.4786 - val_accuracy: 0.8488 - 135s/epoch - 172ms/step\n",
            "Epoch 30/100\n",
            "782/782 - 134s - loss: 0.3763 - accuracy: 0.8711 - val_loss: 0.4401 - val_accuracy: 0.8618 - 134s/epoch - 172ms/step\n",
            "Epoch 31/100\n",
            "782/782 - 138s - loss: 0.3624 - accuracy: 0.8766 - val_loss: 0.4932 - val_accuracy: 0.8399 - 138s/epoch - 176ms/step\n",
            "Epoch 32/100\n",
            "782/782 - 137s - loss: 0.3513 - accuracy: 0.8791 - val_loss: 0.4486 - val_accuracy: 0.8589 - 137s/epoch - 176ms/step\n",
            "Epoch 33/100\n",
            "782/782 - 135s - loss: 0.3400 - accuracy: 0.8843 - val_loss: 0.4680 - val_accuracy: 0.8624 - 135s/epoch - 173ms/step\n",
            "Epoch 34/100\n",
            "782/782 - 136s - loss: 0.3314 - accuracy: 0.8861 - val_loss: 0.4520 - val_accuracy: 0.8628 - 136s/epoch - 174ms/step\n",
            "Epoch 35/100\n",
            "782/782 - 135s - loss: 0.3232 - accuracy: 0.8897 - val_loss: 0.4301 - val_accuracy: 0.8600 - 135s/epoch - 173ms/step\n",
            "Epoch 36/100\n",
            "782/782 - 136s - loss: 0.3227 - accuracy: 0.8903 - val_loss: 0.4430 - val_accuracy: 0.8578 - 136s/epoch - 174ms/step\n",
            "Epoch 37/100\n",
            "782/782 - 136s - loss: 0.3074 - accuracy: 0.8959 - val_loss: 0.4059 - val_accuracy: 0.8698 - 136s/epoch - 174ms/step\n",
            "Epoch 38/100\n",
            "782/782 - 136s - loss: 0.3008 - accuracy: 0.8963 - val_loss: 0.4533 - val_accuracy: 0.8654 - 136s/epoch - 174ms/step\n",
            "Epoch 39/100\n",
            "782/782 - 136s - loss: 0.2993 - accuracy: 0.8982 - val_loss: 0.4269 - val_accuracy: 0.8717 - 136s/epoch - 174ms/step\n",
            "Epoch 40/100\n",
            "782/782 - 135s - loss: 0.2852 - accuracy: 0.9019 - val_loss: 0.4298 - val_accuracy: 0.8694 - 135s/epoch - 172ms/step\n",
            "Epoch 41/100\n",
            "782/782 - 135s - loss: 0.2833 - accuracy: 0.9022 - val_loss: 0.4850 - val_accuracy: 0.8499 - 135s/epoch - 172ms/step\n",
            "Epoch 42/100\n",
            "782/782 - 138s - loss: 0.2778 - accuracy: 0.9046 - val_loss: 0.4963 - val_accuracy: 0.8534 - 138s/epoch - 176ms/step\n",
            "Epoch 43/100\n",
            "782/782 - 143s - loss: 0.2734 - accuracy: 0.9063 - val_loss: 0.4306 - val_accuracy: 0.8771 - 143s/epoch - 183ms/step\n",
            "Epoch 44/100\n",
            "782/782 - 139s - loss: 0.2690 - accuracy: 0.9085 - val_loss: 0.4209 - val_accuracy: 0.8779 - 139s/epoch - 178ms/step\n",
            "Epoch 45/100\n",
            "782/782 - 138s - loss: 0.2594 - accuracy: 0.9113 - val_loss: 0.4243 - val_accuracy: 0.8806 - 138s/epoch - 177ms/step\n",
            "Epoch 46/100\n"
          ]
        }
      ],
      "source": [
        "cnn.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n",
        "hist=cnn.fit(x_train,y_train,batch_size=64,epochs=100,validation_data=(x_test,y_test),verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3YT-4bF6E0E"
      },
      "outputs": [],
      "source": [
        "res=cnn.evaluate(x_test,y_test,verbose=0)\n",
        "print('정확률=',res[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okWYhVqc6Ln0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Accuracy graph')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Loss graph')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'])\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMaiVNuIcv5uGJlUcDzioVB",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}